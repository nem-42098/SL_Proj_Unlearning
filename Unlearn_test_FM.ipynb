{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a href=\"https://colab.research.google.com/github/nem-42098/SL_Proj_Unlearning/blob/main/Unlearn_test_FM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCIXLmbpKuwo",
        "outputId": "f0452157-f739-4f42-c2c7-5d248ac5facc"
      },
      "outputs": [],
      "source": [
        "# !git clone https://github.com/nem-42098/SL_Proj_Unlearning.git\n",
        "# import os\n",
        "# os.chdir('/content/SL_Proj_Unlearning')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6CbLaIs8Kuwq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyJgdsOfKuwr"
      },
      "source": [
        "### Load Pre-Trained VGG network\n",
        "> #### https://github.com/chenyaofo\n",
        "> ### Note: There is some issue with using Batch Norm before ReLu as it creates a bias in the network. So people exchange the order between the two for tackling the bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wvUMz6DKuwr",
        "outputId": "8b291d56-9a33-417f-a4ef-0d43d3bb4dbc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (10): ReLU(inplace=True)\n",
              "    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (17): ReLU(inplace=True)\n",
              "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (24): ReLU(inplace=True)\n",
              "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=512, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "### First time when you wan to download the model\n",
        "device=torch.device('cuda')\n",
        "model = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar10_vgg11_bn\", pretrained=True)\n",
        "model\n",
        "# model=model.to(device)\n",
        "### For future uses:Loading from the local\n",
        "\n",
        "# model_1=torch.hub.load(\"C:/Users/nmura/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\",'hubconf.py',source='local')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqWzDJ7YKuwr"
      },
      "source": [
        "### Check which pre-trained model are available:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSxUWBRyKuwr",
        "outputId": "22605340-a9f4-46cf-fdc0-71e03ffda65b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/chenyaofo/pytorch-cifar-models/zipball/master\" to C:\\Users\\nmura/.cache\\torch\\hub\\master.zip\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['cifar100_mobilenetv2_x0_5',\n",
              " 'cifar100_mobilenetv2_x0_75',\n",
              " 'cifar100_mobilenetv2_x1_0',\n",
              " 'cifar100_mobilenetv2_x1_4',\n",
              " 'cifar100_repvgg_a0',\n",
              " 'cifar100_repvgg_a1',\n",
              " 'cifar100_repvgg_a2',\n",
              " 'cifar100_resnet20',\n",
              " 'cifar100_resnet32',\n",
              " 'cifar100_resnet44',\n",
              " 'cifar100_resnet56',\n",
              " 'cifar100_shufflenetv2_x0_5',\n",
              " 'cifar100_shufflenetv2_x1_0',\n",
              " 'cifar100_shufflenetv2_x1_5',\n",
              " 'cifar100_shufflenetv2_x2_0',\n",
              " 'cifar100_vgg11_bn',\n",
              " 'cifar100_vgg13_bn',\n",
              " 'cifar100_vgg16_bn',\n",
              " 'cifar100_vgg19_bn',\n",
              " 'cifar100_vit_b16',\n",
              " 'cifar100_vit_b32',\n",
              " 'cifar100_vit_h14',\n",
              " 'cifar100_vit_l16',\n",
              " 'cifar100_vit_l32',\n",
              " 'cifar10_mobilenetv2_x0_5',\n",
              " 'cifar10_mobilenetv2_x0_75',\n",
              " 'cifar10_mobilenetv2_x1_0',\n",
              " 'cifar10_mobilenetv2_x1_4',\n",
              " 'cifar10_repvgg_a0',\n",
              " 'cifar10_repvgg_a1',\n",
              " 'cifar10_repvgg_a2',\n",
              " 'cifar10_resnet20',\n",
              " 'cifar10_resnet32',\n",
              " 'cifar10_resnet44',\n",
              " 'cifar10_resnet56',\n",
              " 'cifar10_shufflenetv2_x0_5',\n",
              " 'cifar10_shufflenetv2_x1_0',\n",
              " 'cifar10_shufflenetv2_x1_5',\n",
              " 'cifar10_shufflenetv2_x2_0',\n",
              " 'cifar10_vgg11_bn',\n",
              " 'cifar10_vgg13_bn',\n",
              " 'cifar10_vgg16_bn',\n",
              " 'cifar10_vgg19_bn',\n",
              " 'cifar10_vit_b16',\n",
              " 'cifar10_vit_b32',\n",
              " 'cifar10_vit_h14',\n",
              " 'cifar10_vit_l16',\n",
              " 'cifar10_vit_l32']"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.hub.list(\"chenyaofo/pytorch-cifar-models\", force_reload=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2OwEFlMKuws"
      },
      "source": [
        "### Downlaoding the Dataset and Creating the Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-01GV7HHKuws",
        "outputId": "428b3ea3-bcb0-4e87-d2aa-dfe2ab381588"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "### Transformation\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "       (0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)\n",
        "    )\n",
        "])\n",
        "### Pytorch Datasets\n",
        "train_dataset = torchvision.datasets.CIFAR10(\n",
        "    root= './data', train = True,\n",
        "    download =True, transform = transform)\n",
        "test_dataset = torchvision.datasets.CIFAR10(\n",
        "    root= './data', train = False,\n",
        "    download =True, transform = transform)\n",
        "### Dataloaders\n",
        "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
        "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cclKNSe-Kuws",
        "outputId": "94d263ec-838a-45e8-c338-9f298847ac15"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOZabokbKuwt"
      },
      "source": [
        "### Create the Forget Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-wGG5RC2LW7m"
      },
      "outputs": [],
      "source": [
        "# Define the classes\n",
        "classes = ['forget', 'retain']\n",
        "\n",
        "# Create a dictionary to store datasets for each class\n",
        "class_datasets = {class_name: [] for class_name in classes}\n",
        "\n",
        "# Iterate through the CIFAR-10 dataset and split it into class-specific subsets\n",
        "for image, label in train_dataset:\n",
        "  if label == 1:\n",
        "    class_datasets['forget'].append((image, label))\n",
        "\n",
        "  else:\n",
        "      class_datasets['retain'].append((image, label))\n",
        "\n",
        "# You now have class-specific subsets in the class_datasets dict\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqTeFK7hKuwu"
      },
      "source": [
        "#### Forget and Retain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "RbO79fHuKuwu"
      },
      "outputs": [],
      "source": [
        "# Class split\n",
        "retain_dataloader = torch.utils.data.DataLoader(class_datasets['retain'], batch_size=128, shuffle=True, num_workers=2)\n",
        "forget_dataloader = torch.utils.data.DataLoader(class_datasets['forget'], batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "# Random split\n",
        "# train_split_dataset,forget_split_dataset=torch.utils.data.random_split(train_dataset,lengths=[45000,5000])\n",
        "# retain_dataloader = torch.utils.data.DataLoader(train_split_dataset,  batch_size=128, shuffle=True, num_workers=2)\n",
        "# forget_dataloader = torch.utils.data.DataLoader(forget_split_dataset, batch_size=128, shuffle=True, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Unlearner class\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Using the Lower precision based model. \n",
        "> ### There is some problems with this method. Because the counterpart gives better result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter Type check when pushed to GPU torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Model is on CUDA (GPU)\n",
            "Parameter Type check torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:1553\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter Type check when pushed to GPU torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Model is on CUDA (GPU)\n",
            "Parameter Type check torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:18643\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter Type check when pushed to GPU torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Model is on CUDA (GPU)\n",
            "Parameter Type check torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:35732\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter Type check when pushed to GPU torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Model is on CUDA (GPU)\n",
            "Parameter Type check torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:52822\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter Type check when pushed to GPU torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Model is on CUDA (GPU)\n",
            "Parameter Type check torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:69912\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter Type check when pushed to GPU torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Model is on CUDA (GPU)\n",
            "Parameter Type check torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:87001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter Type check when pushed to GPU torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Model is on CUDA (GPU)\n",
            "Parameter Type check torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:104091\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter Type check when pushed to GPU torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Model is on CUDA (GPU)\n",
            "Parameter Type check torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:121180\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter Type check when pushed to GPU torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Model is on CUDA (GPU)\n",
            "Parameter Type check torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:138270\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter Type check when pushed to GPU torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Model is on CUDA (GPU)\n",
            "Parameter Type check torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:155360\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter Type check when pushed to GPU torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Model is on CUDA (GPU)\n",
            "Parameter Type check torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:15536\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter Type check when pushed to GPU torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Model is on CUDA (GPU)\n",
            "Parameter Type check torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:31072\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter Type check when pushed to GPU torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Model is on CUDA (GPU)\n",
            "Parameter Type check torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:46608\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter Type check when pushed to GPU torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Model is on CUDA (GPU)\n",
            "Parameter Type check torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:62144\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter Type check when pushed to GPU torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Model is on CUDA (GPU)\n",
            "Parameter Type check torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:77680\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter Type check when pushed to GPU torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Model is on CUDA (GPU)\n",
            "Parameter Type check torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:93216\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter Type check when pushed to GPU torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Model is on CUDA (GPU)\n",
            "Parameter Type check torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:108752\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter Type check when pushed to GPU torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Model is on CUDA (GPU)\n",
            "Parameter Type check torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:124288\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter Type check when pushed to GPU torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Model is on CUDA (GPU)\n",
            "Parameter Type check torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:139824\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter Type check when pushed to GPU torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Model is on CUDA (GPU)\n",
            "Parameter Type check torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:155360\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter Type check when pushed to GPU torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Model is on CUDA (GPU)\n",
            "Parameter Type check torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:310720\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter Type check when pushed to GPU torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Model is on CUDA (GPU)\n",
            "Parameter Type check torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:621440\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter Type check when pushed to GPU torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Model is on CUDA (GPU)\n",
            "Parameter Type check torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:932160\n"
          ]
        }
      ],
      "source": [
        "from tools.Unlearner_FM_precision import Unlearner_FM_precision\n",
        "r_perf=[]\n",
        "\n",
        "R=list(np.linspace(0.001,0.1,10))\n",
        "R+=list(np.linspace(0.01,0.1,10))\n",
        "R+=[0.2,0.4,0.6]\n",
        "for i in R:\n",
        "    model = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar10_vgg11_bn\", pretrained=True)\n",
        "    torch.cuda.empty_cache()\n",
        "    unlearner = Unlearner_FM_precision(i,model, lr = 1e-6)\n",
        "    ### Getting the new model masked model\n",
        "\n",
        "    new_model, mask_index,num_of_param=unlearner.Fisher_Masking(retain_dataloader,forget_dataloader)\n",
        "\n",
        "    forget_perf=Unlearner_FM_precision.test(new_model,forget_dataloader,'cuda')\n",
        "    retain_perf=Unlearner_FM_precision.test(new_model,retain_dataloader,'cuda')\n",
        "    test_perf=Unlearner_FM_precision.test(new_model,testloader,'cuda')\n",
        "\n",
        "    r_perf.append([forget_perf,retain_perf,test_perf])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[0.99, 0.9992444444444445, 0.9174],\n",
              " [0.9934, 0.9991111111111111, 0.9178],\n",
              " [0.9882, 0.9975777777777778, 0.9115],\n",
              " [0.9708, 0.9993111111111111, 0.9138],\n",
              " [0.9952, 0.9982888888888889, 0.9144],\n",
              " [0.9922, 0.9974222222222222, 0.9111],\n",
              " [0.991, 0.9951111111111111, 0.9068],\n",
              " [0.9924, 0.9943555555555555, 0.905],\n",
              " [0.9806, 0.9931333333333333, 0.9031],\n",
              " [0.9854, 0.9922222222222222, 0.9031],\n",
              " [0.9954, 0.9993333333333333, 0.9183],\n",
              " [0.9812, 0.9956888888888888, 0.9092],\n",
              " [0.9872, 0.9987777777777778, 0.9155],\n",
              " [0.9956, 0.9985111111111111, 0.9162],\n",
              " [0.9908, 0.9981333333333333, 0.9132],\n",
              " [0.9782, 0.9747333333333333, 0.8839],\n",
              " [0.991, 0.9957777777777778, 0.9076],\n",
              " [0.9952, 0.9934888888888889, 0.9071],\n",
              " [0.9852, 0.9915333333333334, 0.9011],\n",
              " [0.9944, 0.9938444444444444, 0.9056],\n",
              " [0.1416, 0.8173333333333334, 0.6768],\n",
              " [0.0, 0.1111111111111111, 0.1],\n",
              " [0.0, 0.1111111111111111, 0.1]]"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "r_perf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[0.1822, 0.565, 0.4987],\n",
              " [0.9948, 0.9994666666666666, 0.9186],\n",
              " [0.9908, 0.9979333333333333, 0.9122],\n",
              " [0.9624, 0.9833111111111111, 0.892],\n",
              " [0.9408, 0.9732222222222222, 0.8727],\n",
              " [0.6086, 0.8173333333333334, 0.7206]]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "r_perf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Counterpart: Maintaining the original precision of the model and diverting some operation to CPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished Computing Hessian Diagonal\n",
            "Finished Computing Hessian Diagonal\n",
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:1553\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:3107\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:4660\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:6214\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:7768\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:9321\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:10875\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:12428\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:13982\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:15536\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:15536\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:31072\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:46608\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:62144\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:77680\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:93216\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:108752\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:124288\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:139824\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:155360\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:310720\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:621440\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:932160\n"
          ]
        }
      ],
      "source": [
        "# from tools.Unlearner_FM import Unlearner_FM\n",
        "# torch.cuda.empty_cache()\n",
        "# model = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar10_vgg11_bn\", pretrained=True)\n",
        "# unlearner_1 = Unlearner_FM(0.02,model, lr = 1e-6)\n",
        "\n",
        "\n",
        "from tools.Unlearner_FM import Unlearner_FM\n",
        "r_perf_1=[]\n",
        "\n",
        "R=list(np.linspace(0.001,0.01,10))\n",
        "R+=list(np.linspace(0.01,0.1,10))\n",
        "R+=[0.2,0.4,0.6]\n",
        "forget_path='./data/forget_hess_cifar10_vgg11_class1.pt'\n",
        "retain_path='./data/retain_hess_cifar10_vgg11_class1.pt'\n",
        "for i in R:\n",
        "    model = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar10_vgg11_bn\", pretrained=True)\n",
        "    torch.cuda.empty_cache()\n",
        "    unlearner = Unlearner_FM(i,model, lr = 1e-6)\n",
        "    ### Getting the new model masked model\n",
        "\n",
        "    new_model_1, mask_index_1,num_of_param_1=unlearner.Fisher_Masking(retain_dataloader,forget_dataloader,forget_hess_path=forget_path,retain_hess_path=retain_path)\n",
        "\n",
        "\n",
        "    forget_perf=Unlearner_FM.test(new_model_1,forget_dataloader,'cuda')\n",
        "    retain_perf=Unlearner_FM.test(new_model_1,retain_dataloader,'cuda')\n",
        "    test_perf=Unlearner_FM.test(new_model_1,testloader,'cuda')\n",
        "\n",
        "    r_perf_1.append([forget_perf,retain_perf,test_perf])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[0.007, 0.9988222222222222, 0.8262],\n",
              " [0.0004, 0.9875777777777778, 0.8041],\n",
              " [0.0002, 0.9852, 0.8024],\n",
              " [0.0008, 0.9841555555555556, 0.8016],\n",
              " [0.0, 0.9842666666666666, 0.8005],\n",
              " [0.0, 0.9830888888888889, 0.7989],\n",
              " [0.0002, 0.9830444444444445, 0.7983],\n",
              " [0.0002, 0.9821777777777778, 0.7975],\n",
              " [0.0, 0.9818222222222223, 0.7985],\n",
              " [0.0002, 0.9808, 0.7968],\n",
              " [0.0, 0.9809111111111111, 0.7969],\n",
              " [0.0004, 0.9811777777777778, 0.7967],\n",
              " [0.0, 0.9799555555555556, 0.7952],\n",
              " [0.0, 0.9788444444444444, 0.7918],\n",
              " [0.0, 0.9779111111111111, 0.7876],\n",
              " [0.0, 0.9748888888888889, 0.7857],\n",
              " [0.0, 0.9716, 0.7828],\n",
              " [0.0, 0.9694222222222222, 0.7803],\n",
              " [0.0, 0.9661555555555555, 0.7755],\n",
              " [0.0, 0.9627111111111111, 0.7752],\n",
              " [0.0, 0.8913555555555556, 0.7168],\n",
              " [0.0, 0.8678, 0.6981],\n",
              " [0.0, 0.7358, 0.5921]]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "r_perf_1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run the unlearning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished Computing Hessian Diagonal\n",
            "Finished Computing Hessian Diagonal\n",
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:31072\n"
          ]
        }
      ],
      "source": [
        "### Getting the new model masked model\n",
        "\n",
        "new_model_1, mask_index_1,num_of_param_1=unlearner_1.Fisher_Masking(retain_dataloader,forget_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Unlearner_FM.test(new_model_1,forget_dataloader,'cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9576666666666667"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Unlearner_FM.test(new_model_1,retain_dataloader,'cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7854"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Unlearner_FM.test(new_model_1,testloader,'cuda')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that the unlearning process may need many epochs in the erasure phase to converge. We could also try to increase the learning rate for faster convergence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "log_df = pd.DataFrame.from_records(unlearner.log, columns=['phase', 'epoch', 'batch', 'tp', 'n', 'loss'])\n",
        "unlearn_history = log_df.groupby(['phase', 'epoch']).agg({'tp':sum, 'n':sum, 'loss': 'mean'}).reset_index()\n",
        "unlearn_history['accuracy'] = unlearn_history.tp / unlearn_history.n\n",
        "unlearn_history.loc[unlearn_history.phase == 'erasure', 'loss_scale'] = unlearn_history.loc[unlearn_history.phase == 'erasure', 'loss'] /unlearn_history.loc[unlearn_history.phase == 'erasure', 'loss'].max() \n",
        "unlearn_history.loc[unlearn_history.phase == 'retrain', 'loss_scale'] = unlearn_history.loc[unlearn_history.phase == 'retrain', 'loss'] /unlearn_history.loc[unlearn_history.phase == 'retrain', 'loss'].max() \n",
        "\n",
        "sns.lineplot(data = unlearn_history, x = 'epoch', y='loss_scale', hue='phase')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Check model performance\n",
        "We now try check the model performance on the retain and forget set. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "models = {'original':model, 'dumb':unlearner.dumb_model, 'erased':unlearner.erased_model, 'retrained':unlearner.retrained_model}\n",
        "dataloaders = {'retain':retain_dataloader, 'forget':forget_dataloader, 'test':testloader}\n",
        "\n",
        "performances = []\n",
        "for model_name, m in models.items():\n",
        "  for dl_name, dl in dataloaders.items():\n",
        "    acc = test(m, dl)\n",
        "    performances.append((model_name, dl_name, acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Strangely the dumb network has 0% performance on the forget set, and this may have a negative impact, note that the performance on the forget set is even too low (we expected 10%, not less).\n",
        "\n",
        "Outside of that we note that this procedure works great for the retain and test which are fitted very nicely, and we can even see that there's a big leap in performance from the erased model to the retrained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "perf_df = pd.DataFrame.from_records(performances, columns=['model', 'data_partition', 'accuracy'])\n",
        "\n",
        "tb = pd.pivot_table(perf_df, index='data_partition', columns='model', values='accuracy')\n",
        "sns.heatmap(tb, annot = True, fmt='.2%')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
