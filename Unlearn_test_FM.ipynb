{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a href=\"https://colab.research.google.com/github/nem-42098/SL_Proj_Unlearning/blob/main/Unlearn_test_FM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCIXLmbpKuwo",
        "outputId": "f0452157-f739-4f42-c2c7-5d248ac5facc"
      },
      "outputs": [],
      "source": [
        "# !git clone --branch code-refactor https://github.com/nem-42098/SL_Proj_Unlearning.git\n",
        "# import os\n",
        "# os.chdir('/content/SL_Proj_Unlearning')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6CbLaIs8Kuwq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyJgdsOfKuwr"
      },
      "source": [
        "### Load Pre-Trained VGG network\n",
        "> #### https://github.com/chenyaofo\n",
        "> ### Note: There is some issue with using Batch Norm before ReLu as it creates a bias in the network. So people exchange the order between the two for tackling the bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wvUMz6DKuwr",
        "outputId": "8b291d56-9a33-417f-a4ef-0d43d3bb4dbc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (10): ReLU(inplace=True)\n",
              "    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (17): ReLU(inplace=True)\n",
              "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (24): ReLU(inplace=True)\n",
              "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=512, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "### First time when you wan to download the model\n",
        "device=torch.device('cuda')\n",
        "model = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar10_vgg11_bn\", pretrained=True)\n",
        "model\n",
        "# model=model.to(device)\n",
        "### For future uses:Loading from the local\n",
        "\n",
        "# model_1=torch.hub.load(\"C:/Users/nmura/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\",'hubconf.py',source='local')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqWzDJ7YKuwr"
      },
      "source": [
        "### Check which pre-trained model are available:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSxUWBRyKuwr",
        "outputId": "22605340-a9f4-46cf-fdc0-71e03ffda65b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/chenyaofo/pytorch-cifar-models/zipball/master\" to C:\\Users\\nmura/.cache\\torch\\hub\\master.zip\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['cifar100_mobilenetv2_x0_5',\n",
              " 'cifar100_mobilenetv2_x0_75',\n",
              " 'cifar100_mobilenetv2_x1_0',\n",
              " 'cifar100_mobilenetv2_x1_4',\n",
              " 'cifar100_repvgg_a0',\n",
              " 'cifar100_repvgg_a1',\n",
              " 'cifar100_repvgg_a2',\n",
              " 'cifar100_resnet20',\n",
              " 'cifar100_resnet32',\n",
              " 'cifar100_resnet44',\n",
              " 'cifar100_resnet56',\n",
              " 'cifar100_shufflenetv2_x0_5',\n",
              " 'cifar100_shufflenetv2_x1_0',\n",
              " 'cifar100_shufflenetv2_x1_5',\n",
              " 'cifar100_shufflenetv2_x2_0',\n",
              " 'cifar100_vgg11_bn',\n",
              " 'cifar100_vgg13_bn',\n",
              " 'cifar100_vgg16_bn',\n",
              " 'cifar100_vgg19_bn',\n",
              " 'cifar100_vit_b16',\n",
              " 'cifar100_vit_b32',\n",
              " 'cifar100_vit_h14',\n",
              " 'cifar100_vit_l16',\n",
              " 'cifar100_vit_l32',\n",
              " 'cifar10_mobilenetv2_x0_5',\n",
              " 'cifar10_mobilenetv2_x0_75',\n",
              " 'cifar10_mobilenetv2_x1_0',\n",
              " 'cifar10_mobilenetv2_x1_4',\n",
              " 'cifar10_repvgg_a0',\n",
              " 'cifar10_repvgg_a1',\n",
              " 'cifar10_repvgg_a2',\n",
              " 'cifar10_resnet20',\n",
              " 'cifar10_resnet32',\n",
              " 'cifar10_resnet44',\n",
              " 'cifar10_resnet56',\n",
              " 'cifar10_shufflenetv2_x0_5',\n",
              " 'cifar10_shufflenetv2_x1_0',\n",
              " 'cifar10_shufflenetv2_x1_5',\n",
              " 'cifar10_shufflenetv2_x2_0',\n",
              " 'cifar10_vgg11_bn',\n",
              " 'cifar10_vgg13_bn',\n",
              " 'cifar10_vgg16_bn',\n",
              " 'cifar10_vgg19_bn',\n",
              " 'cifar10_vit_b16',\n",
              " 'cifar10_vit_b32',\n",
              " 'cifar10_vit_h14',\n",
              " 'cifar10_vit_l16',\n",
              " 'cifar10_vit_l32']"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.hub.list(\"chenyaofo/pytorch-cifar-models\", force_reload=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2OwEFlMKuws"
      },
      "source": [
        "### Downlaoding the Dataset and Creating the Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-01GV7HHKuws",
        "outputId": "428b3ea3-bcb0-4e87-d2aa-dfe2ab381588"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "### Transformation\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "       (0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)\n",
        "    )\n",
        "])\n",
        "### Pytorch Datasets\n",
        "train_dataset = torchvision.datasets.CIFAR10(\n",
        "    root= './data', train = True,\n",
        "    download =True, transform = transform)\n",
        "test_dataset = torchvision.datasets.CIFAR10(\n",
        "    root= './data', train = False,\n",
        "    download =True, transform = transform)\n",
        "### Dataloaders\n",
        "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
        "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cclKNSe-Kuws",
        "outputId": "94d263ec-838a-45e8-c338-9f298847ac15"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOZabokbKuwt"
      },
      "source": [
        "### Create the Forget Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-wGG5RC2LW7m"
      },
      "outputs": [],
      "source": [
        "# Define the classes\n",
        "classes = ['forget', 'retain']\n",
        "\n",
        "# Create a dictionary to store datasets for each class\n",
        "class_datasets = {class_name: [] for class_name in classes}\n",
        "\n",
        "# Iterate through the CIFAR-10 dataset and split it into class-specific subsets\n",
        "for image, label in train_dataset:\n",
        "  if label == 1:\n",
        "    class_datasets['forget'].append((image, label))\n",
        "\n",
        "  else:\n",
        "      class_datasets['retain'].append((image, label))\n",
        "\n",
        "# You now have class-specific subsets in the class_datasets dict\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqTeFK7hKuwu"
      },
      "source": [
        "#### Forget and Retain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "RbO79fHuKuwu"
      },
      "outputs": [],
      "source": [
        "# Class split\n",
        "retain_dataloader = torch.utils.data.DataLoader(class_datasets['retain'], batch_size=128, shuffle=True, num_workers=2)\n",
        "forget_dataloader = torch.utils.data.DataLoader(class_datasets['forget'], batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "# Random split\n",
        "# train_split_dataset,forget_split_dataset=torch.utils.data.random_split(train_dataset,lengths=[45000,5000])\n",
        "# retain_dataloader = torch.utils.data.DataLoader(train_split_dataset,  batch_size=128, shuffle=True, num_workers=2)\n",
        "# forget_dataloader = torch.utils.data.DataLoader(forget_split_dataset, batch_size=128, shuffle=True, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Unlearner class\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Using the Lower precision based model. \n",
        "> ### There is some problems with this method. Because the counterpart gives better result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter Type check when pushed to GPU torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Model is on CUDA (GPU)\n",
            "Parameter Type check torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:1553\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter Type check when pushed to GPU torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Model is on CUDA (GPU)\n",
            "Parameter Type check torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:18643\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter Type check when pushed to GPU torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Model is on CUDA (GPU)\n",
            "Parameter Type check torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:35732\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter Type check when pushed to GPU torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Model is on CUDA (GPU)\n",
            "Parameter Type check torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:52822\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter Type check when pushed to GPU torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Model is on CUDA (GPU)\n",
            "Parameter Type check torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:69912\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter Type check when pushed to GPU torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Model is on CUDA (GPU)\n",
            "Parameter Type check torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:87001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter Type check when pushed to GPU torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Model is on CUDA (GPU)\n",
            "Parameter Type check torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:104091\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter Type check when pushed to GPU torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Model is on CUDA (GPU)\n",
            "Parameter Type check torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:121180\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter Type check when pushed to GPU torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Model is on CUDA (GPU)\n",
            "Parameter Type check torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:138270\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter Type check when pushed to GPU torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Model is on CUDA (GPU)\n",
            "Parameter Type check torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:155360\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter Type check when pushed to GPU torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Model is on CUDA (GPU)\n",
            "Parameter Type check torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:15536\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter Type check when pushed to GPU torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Model is on CUDA (GPU)\n",
            "Parameter Type check torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:31072\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter Type check when pushed to GPU torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Model is on CUDA (GPU)\n",
            "Parameter Type check torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:46608\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter Type check when pushed to GPU torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Model is on CUDA (GPU)\n",
            "Parameter Type check torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:62144\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter Type check when pushed to GPU torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Model is on CUDA (GPU)\n",
            "Parameter Type check torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:77680\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter Type check when pushed to GPU torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Model is on CUDA (GPU)\n",
            "Parameter Type check torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:93216\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter Type check when pushed to GPU torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Model is on CUDA (GPU)\n",
            "Parameter Type check torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:108752\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter Type check when pushed to GPU torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Model is on CUDA (GPU)\n",
            "Parameter Type check torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:124288\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter Type check when pushed to GPU torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Model is on CUDA (GPU)\n",
            "Parameter Type check torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:139824\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter Type check when pushed to GPU torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Model is on CUDA (GPU)\n",
            "Parameter Type check torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:155360\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter Type check when pushed to GPU torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Model is on CUDA (GPU)\n",
            "Parameter Type check torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:310720\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter Type check when pushed to GPU torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Model is on CUDA (GPU)\n",
            "Parameter Type check torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:621440\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter Type check when pushed to GPU torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Model is on CUDA (GPU)\n",
            "Parameter Type check torch.float16\n",
            "Finished Computing Hessian Diagonal\n",
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:932160\n"
          ]
        }
      ],
      "source": [
        "from tools.Unlearner_FM_precision import Unlearner_FM_precision\n",
        "r_perf=[]\n",
        "\n",
        "R=list(np.linspace(0.001,0.1,10))\n",
        "R+=list(np.linspace(0.01,0.1,10))\n",
        "R+=[0.2,0.4,0.6]\n",
        "for i in R:\n",
        "    model = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar10_vgg11_bn\", pretrained=True)\n",
        "    torch.cuda.empty_cache()\n",
        "    unlearner = Unlearner_FM_precision(i,model, lr = 1e-6)\n",
        "    ### Getting the new model masked model\n",
        "\n",
        "    new_model, mask_index,num_of_param=unlearner.Fisher_Masking(retain_dataloader,forget_dataloader)\n",
        "\n",
        "    forget_perf=Unlearner_FM_precision.test(new_model,forget_dataloader,'cuda')\n",
        "    retain_perf=Unlearner_FM_precision.test(new_model,retain_dataloader,'cuda')\n",
        "    test_perf=Unlearner_FM_precision.test(new_model,testloader,'cuda')\n",
        "\n",
        "    r_perf.append([forget_perf,retain_perf,test_perf])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[0.99, 0.9992444444444445, 0.9174],\n",
              " [0.9934, 0.9991111111111111, 0.9178],\n",
              " [0.9882, 0.9975777777777778, 0.9115],\n",
              " [0.9708, 0.9993111111111111, 0.9138],\n",
              " [0.9952, 0.9982888888888889, 0.9144],\n",
              " [0.9922, 0.9974222222222222, 0.9111],\n",
              " [0.991, 0.9951111111111111, 0.9068],\n",
              " [0.9924, 0.9943555555555555, 0.905],\n",
              " [0.9806, 0.9931333333333333, 0.9031],\n",
              " [0.9854, 0.9922222222222222, 0.9031],\n",
              " [0.9954, 0.9993333333333333, 0.9183],\n",
              " [0.9812, 0.9956888888888888, 0.9092],\n",
              " [0.9872, 0.9987777777777778, 0.9155],\n",
              " [0.9956, 0.9985111111111111, 0.9162],\n",
              " [0.9908, 0.9981333333333333, 0.9132],\n",
              " [0.9782, 0.9747333333333333, 0.8839],\n",
              " [0.991, 0.9957777777777778, 0.9076],\n",
              " [0.9952, 0.9934888888888889, 0.9071],\n",
              " [0.9852, 0.9915333333333334, 0.9011],\n",
              " [0.9944, 0.9938444444444444, 0.9056],\n",
              " [0.1416, 0.8173333333333334, 0.6768],\n",
              " [0.0, 0.1111111111111111, 0.1],\n",
              " [0.0, 0.1111111111111111, 0.1]]"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "r_perf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[0.1822, 0.565, 0.4987],\n",
              " [0.9948, 0.9994666666666666, 0.9186],\n",
              " [0.9908, 0.9979333333333333, 0.9122],\n",
              " [0.9624, 0.9833111111111111, 0.892],\n",
              " [0.9408, 0.9732222222222222, 0.8727],\n",
              " [0.6086, 0.8173333333333334, 0.7206]]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "r_perf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Counterpart: Maintaining the original precision of the model and diverting some operation to CPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:1553\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32md:\\Sapienza academic\\SL\\Project\\ML_Unlearn\\Unlearn_test_FM.ipynb Cell 21\u001b[0m line \u001b[0;36m<cell line: 15>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Sapienza%20academic/SL/Project/ML_Unlearn/Unlearn_test_FM.ipynb#X22sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m new_model_1, mask_index_1,num_of_param_1\u001b[39m=\u001b[39munlearner\u001b[39m.\u001b[39mFisher_Masking(retain_dataloader,forget_dataloader,forget_hess_path\u001b[39m=\u001b[39mforget_path,retain_hess_path\u001b[39m=\u001b[39mretain_path)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Sapienza%20academic/SL/Project/ML_Unlearn/Unlearn_test_FM.ipynb#X22sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m forget_perf\u001b[39m=\u001b[39mUnlearner_FM\u001b[39m.\u001b[39mtest(new_model_1,forget_dataloader,\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Sapienza%20academic/SL/Project/ML_Unlearn/Unlearn_test_FM.ipynb#X22sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m retain_perf\u001b[39m=\u001b[39mUnlearner_FM\u001b[39m.\u001b[39;49mtest(new_model_1,retain_dataloader,\u001b[39m'\u001b[39;49m\u001b[39mcuda\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Sapienza%20academic/SL/Project/ML_Unlearn/Unlearn_test_FM.ipynb#X22sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m test_perf\u001b[39m=\u001b[39mUnlearner_FM\u001b[39m.\u001b[39mtest(new_model_1,testloader,\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Sapienza%20academic/SL/Project/ML_Unlearn/Unlearn_test_FM.ipynb#X22sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m r_perf_1\u001b[39m.\u001b[39mappend([forget_perf,retain_perf,test_perf])\n",
            "File \u001b[1;32md:\\Sapienza academic\\SL\\Project\\ML_Unlearn\\tools\\Unlearner_FM.py:313\u001b[0m, in \u001b[0;36mUnlearner_FM.test\u001b[1;34m(model, dataloader, device)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[39m@staticmethod\u001b[39m \n\u001b[0;32m    311\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtest\u001b[39m(model, dataloader,device):\n\u001b[0;32m    312\u001b[0m     tp, n \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m\n\u001b[1;32m--> 313\u001b[0m     \u001b[39mfor\u001b[39;00m X,y \u001b[39min\u001b[39;00m dataloader:\n\u001b[0;32m    314\u001b[0m         X,y \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mto(device), y\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m    316\u001b[0m         \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n",
            "File \u001b[1;32md:\\Anaconda\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:435\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    433\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[0;32m    434\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 435\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
            "File \u001b[1;32md:\\Anaconda\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:381\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    380\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 381\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
            "File \u001b[1;32md:\\Anaconda\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1034\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1027\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1028\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1029\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1030\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1031\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1032\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1033\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1034\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[0;32m   1035\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1036\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
            "File \u001b[1;32md:\\Anaconda\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
            "File \u001b[1;32md:\\Anaconda\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
            "File \u001b[1;32md:\\Anaconda\\lib\\multiprocessing\\context.py:327\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    325\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    326\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_win32\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[1;32m--> 327\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
            "File \u001b[1;32md:\\Anaconda\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[39m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     reduction\u001b[39m.\u001b[39;49mdump(process_obj, to_child)\n\u001b[0;32m     94\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[39mNone\u001b[39;00m)\n",
            "File \u001b[1;32md:\\Anaconda\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(obj, file, protocol\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m     \u001b[39m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     ForkingPickler(file, protocol)\u001b[39m.\u001b[39;49mdump(obj)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# from tools.Unlearner_FM import Unlearner_FM\n",
        "# torch.cuda.empty_cache()\n",
        "# model = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar10_vgg11_bn\", pretrained=True)\n",
        "# unlearner_1 = Unlearner_FM(0.02,model, lr = 1e-6)\n",
        "\n",
        "\n",
        "from tools.Unlearner_FM import Unlearner_FM\n",
        "r_perf_1=[]\n",
        "\n",
        "R=list(np.linspace(0.001,0.01,10))\n",
        "R+=list(np.linspace(0.01,0.1,10))\n",
        "R+=[0.2,0.4,0.6]\n",
        "forget_path='./data/forget_hess_cifar10_vgg11_class1.pt'\n",
        "retain_path='./data/retain_hess_cifar10_vgg11_class1.pt'\n",
        "for i in R:\n",
        "    model = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar10_vgg11_bn\", pretrained=True)\n",
        "    torch.cuda.empty_cache()\n",
        "    unlearner = Unlearner_FM(i,model, lr = 1e-6)\n",
        "    ### Getting the new model masked model\n",
        "\n",
        "    new_model_1, mask_index_1,num_of_param_1=unlearner.Fisher_Masking(retain_dataloader,forget_dataloader,forget_hess_path=forget_path,retain_hess_path=retain_path)\n",
        "\n",
        "\n",
        "    forget_perf=Unlearner_FM.test(new_model_1,forget_dataloader,'cuda')\n",
        "    retain_perf=Unlearner_FM.test(new_model_1,retain_dataloader,'cuda')\n",
        "    test_perf=Unlearner_FM.test(new_model_1,testloader,'cuda')\n",
        "\n",
        "    r_perf_1.append([forget_perf,retain_perf,test_perf])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "R_=[ round(i,3) for i in R ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "df =pd.DataFrame(r_perf_1)\n",
        "df.index=[ i for i in R_]\n",
        "df.columns=['forget','retain','test']\n",
        "sns.lineplot(data=df)\n",
        "plt.xscale('log')\n",
        "plt.xticks(rotation=90)\n",
        "plt.xlabel('Remvoal Ratio')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[0.007, 0.9988222222222222, 0.8262],\n",
              " [0.0004, 0.9875777777777778, 0.8041],\n",
              " [0.0002, 0.9852, 0.8024],\n",
              " [0.0008, 0.9841555555555556, 0.8016],\n",
              " [0.0, 0.9842666666666666, 0.8005],\n",
              " [0.0, 0.9830888888888889, 0.7989],\n",
              " [0.0002, 0.9830444444444445, 0.7983],\n",
              " [0.0002, 0.9821777777777778, 0.7975],\n",
              " [0.0, 0.9818222222222223, 0.7985],\n",
              " [0.0002, 0.9808, 0.7968],\n",
              " [0.0, 0.9809111111111111, 0.7969],\n",
              " [0.0004, 0.9811777777777778, 0.7967],\n",
              " [0.0, 0.9799555555555556, 0.7952],\n",
              " [0.0, 0.9788444444444444, 0.7918],\n",
              " [0.0, 0.9779111111111111, 0.7876],\n",
              " [0.0, 0.9748888888888889, 0.7857],\n",
              " [0.0, 0.9716, 0.7828],\n",
              " [0.0, 0.9694222222222222, 0.7803],\n",
              " [0.0, 0.9661555555555555, 0.7755],\n",
              " [0.0, 0.9627111111111111, 0.7752],\n",
              " [0.0, 0.8913555555555556, 0.7168],\n",
              " [0.0, 0.8678, 0.6981],\n",
              " [0.0, 0.7358, 0.5921]]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "r_perf_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:1553\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|         | 1/10 [01:03<09:29, 63.30s/it]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32md:\\Sapienza academic\\SL\\Project\\ML_Unlearn\\Unlearn_test_FM.ipynb Cell 25\u001b[0m line \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Sapienza%20academic/SL/Project/ML_Unlearn/Unlearn_test_FM.ipynb#X64sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m### Getting the new model masked model\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Sapienza%20academic/SL/Project/ML_Unlearn/Unlearn_test_FM.ipynb#X64sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m new_model_1, mask_index_1,num_of_param_1\u001b[39m=\u001b[39munlearner\u001b[39m.\u001b[39mFisher_Masking(retain_dataloader,forget_dataloader,forget_hess_path\u001b[39m=\u001b[39mforget_path,retain_hess_path\u001b[39m=\u001b[39mretain_path)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Sapienza%20academic/SL/Project/ML_Unlearn/Unlearn_test_FM.ipynb#X64sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m new_model_1,epoch_log\u001b[39m=\u001b[39munlearner\u001b[39m.\u001b[39;49mfine_tune(new_model_1,retain_dataloader)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Sapienza%20academic/SL/Project/ML_Unlearn/Unlearn_test_FM.ipynb#X64sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m forget_perf\u001b[39m=\u001b[39mUnlearner_FM\u001b[39m.\u001b[39mtest(new_model_1,forget_dataloader,\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Sapienza%20academic/SL/Project/ML_Unlearn/Unlearn_test_FM.ipynb#X64sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m retain_perf\u001b[39m=\u001b[39mUnlearner_FM\u001b[39m.\u001b[39mtest(new_model_1,retain_dataloader,\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m)\n",
            "File \u001b[1;32md:\\Sapienza academic\\SL\\Project\\ML_Unlearn\\tools\\Unlearner_FM.py:346\u001b[0m, in \u001b[0;36mUnlearner_FM.fine_tune\u001b[1;34m(self, model, dataloader, epochs)\u001b[0m\n\u001b[0;32m    339\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m tq(\u001b[39mrange\u001b[39m(epochs)):\n\u001b[0;32m    340\u001b[0m     \u001b[39m### iterate over the forget_dataloader\u001b[39;00m\n\u001b[0;32m    341\u001b[0m     \u001b[39m### batch _loss\u001b[39;00m\n\u001b[0;32m    342\u001b[0m     loss_epoch \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m--> 346\u001b[0m     \u001b[39mfor\u001b[39;00m i, (inputs, targets) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataloader):\n\u001b[0;32m    347\u001b[0m \n\u001b[0;32m    348\u001b[0m         \n\u001b[0;32m    349\u001b[0m         \u001b[39m### GPU push\u001b[39;00m\n\u001b[0;32m    350\u001b[0m         inputs, targets \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mto(\n\u001b[0;32m    351\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice), targets\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m    353\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnext\u001b[39m(model\u001b[39m.\u001b[39mparameters())\u001b[39m.\u001b[39mis_cuda:\n",
            "File \u001b[1;32md:\\Anaconda\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[1;32md:\\Anaconda\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1305\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1302\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1303\u001b[0m     \u001b[39m# no valid `self._rcvd_idx` is found (i.e., didn't break)\u001b[39;00m\n\u001b[0;32m   1304\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_persistent_workers:\n\u001b[1;32m-> 1305\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_shutdown_workers()\n\u001b[0;32m   1306\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n\u001b[0;32m   1308\u001b[0m \u001b[39m# Now `self._rcvd_idx` is the batch index we want to fetch\u001b[39;00m\n\u001b[0;32m   1309\u001b[0m \n\u001b[0;32m   1310\u001b[0m \u001b[39m# Check if the next sample has already been generated\u001b[39;00m\n",
            "File \u001b[1;32md:\\Anaconda\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1430\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._shutdown_workers\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1425\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mark_worker_as_unavailable(worker_id, shutdown\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m   1426\u001b[0m \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers:\n\u001b[0;32m   1427\u001b[0m     \u001b[39m# We should be able to join here, but in case anything went\u001b[39;00m\n\u001b[0;32m   1428\u001b[0m     \u001b[39m# wrong, we set a timeout and if the workers fail to join,\u001b[39;00m\n\u001b[0;32m   1429\u001b[0m     \u001b[39m# they are killed in the `finally` block.\u001b[39;00m\n\u001b[1;32m-> 1430\u001b[0m     w\u001b[39m.\u001b[39;49mjoin(timeout\u001b[39m=\u001b[39;49m_utils\u001b[39m.\u001b[39;49mMP_STATUS_CHECK_INTERVAL)\n\u001b[0;32m   1431\u001b[0m \u001b[39mfor\u001b[39;00m q \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues:\n\u001b[0;32m   1432\u001b[0m     q\u001b[39m.\u001b[39mcancel_join_thread()\n",
            "File \u001b[1;32md:\\Anaconda\\lib\\multiprocessing\\process.py:149\u001b[0m, in \u001b[0;36mBaseProcess.join\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parent_pid \u001b[39m==\u001b[39m os\u001b[39m.\u001b[39mgetpid(), \u001b[39m'\u001b[39m\u001b[39mcan only join a child process\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    148\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m, \u001b[39m'\u001b[39m\u001b[39mcan only join a started process\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m--> 149\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_popen\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    150\u001b[0m \u001b[39mif\u001b[39;00m res \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    151\u001b[0m     _children\u001b[39m.\u001b[39mdiscard(\u001b[39mself\u001b[39m)\n",
            "File \u001b[1;32md:\\Anaconda\\lib\\multiprocessing\\popen_spawn_win32.py:108\u001b[0m, in \u001b[0;36mPopen.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    106\u001b[0m     msecs \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mint\u001b[39m(timeout \u001b[39m*\u001b[39m \u001b[39m1000\u001b[39m \u001b[39m+\u001b[39m \u001b[39m0.5\u001b[39m))\n\u001b[1;32m--> 108\u001b[0m res \u001b[39m=\u001b[39m _winapi\u001b[39m.\u001b[39;49mWaitForSingleObject(\u001b[39mint\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle), msecs)\n\u001b[0;32m    109\u001b[0m \u001b[39mif\u001b[39;00m res \u001b[39m==\u001b[39m _winapi\u001b[39m.\u001b[39mWAIT_OBJECT_0:\n\u001b[0;32m    110\u001b[0m     code \u001b[39m=\u001b[39m _winapi\u001b[39m.\u001b[39mGetExitCodeProcess(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from tools.Unlearner_FM import Unlearner_FM\n",
        "r_perf_2=[]\n",
        "\n",
        "R=list(np.linspace(0.001,0.01,10))\n",
        "R+=list(np.linspace(0.01,0.1,10))\n",
        "R+=[0.2,0.4,0.6]\n",
        "forget_path='./data/forget_hess_cifar10_vgg11_class1.pt'\n",
        "retain_path='./data/retain_hess_cifar10_vgg11_class1.pt'\n",
        "for i in R:\n",
        "    model = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar10_vgg11_bn\", pretrained=True)\n",
        "    torch.cuda.empty_cache()\n",
        "    unlearner = Unlearner_FM(i,model, lr = 1e-6)\n",
        "    ### Getting the new model masked model\n",
        "\n",
        "    new_model_1, mask_index_1,num_of_param_1=unlearner.Fisher_Masking(retain_dataloader,forget_dataloader,forget_hess_path=forget_path,retain_hess_path=retain_path)\n",
        "\n",
        "    new_model_1,epoch_log=unlearner.fine_tune(new_model_1,retain_dataloader)\n",
        "    forget_perf=Unlearner_FM.test(new_model_1,forget_dataloader,'cuda')\n",
        "    retain_perf=Unlearner_FM.test(new_model_1,retain_dataloader,'cuda')\n",
        "    test_perf=Unlearner_FM.test(new_model_1,testloader,'cuda')\n",
        "\n",
        "    r_perf_2.append([forget_perf,retain_perf,test_perf,[epoch_log]])\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run the unlearning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished Computing Hessian Diagonal\n",
            "Finished Computing Hessian Diagonal\n",
            "Total Number of Kernels and Neurons:1553600, Number of masked Paramters:31072\n"
          ]
        }
      ],
      "source": [
        "### Getting the new model masked model\n",
        "\n",
        "new_model_1, mask_index_1,num_of_param_1=unlearner_1.Fisher_Masking(retain_dataloader,forget_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Unlearner_FM.test(new_model_1,forget_dataloader,'cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9576666666666667"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Unlearner_FM.test(new_model_1,retain_dataloader,'cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7854"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Unlearner_FM.test(new_model_1,testloader,'cuda')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that the unlearning process may need many epochs in the erasure phase to converge. We could also try to increase the learning rate for faster convergence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "log_df = pd.DataFrame.from_records(unlearner.log, columns=['phase', 'epoch', 'batch', 'tp', 'n', 'loss'])\n",
        "unlearn_history = log_df.groupby(['phase', 'epoch']).agg({'tp':sum, 'n':sum, 'loss': 'mean'}).reset_index()\n",
        "unlearn_history['accuracy'] = unlearn_history.tp / unlearn_history.n\n",
        "unlearn_history.loc[unlearn_history.phase == 'erasure', 'loss_scale'] = unlearn_history.loc[unlearn_history.phase == 'erasure', 'loss'] /unlearn_history.loc[unlearn_history.phase == 'erasure', 'loss'].max() \n",
        "unlearn_history.loc[unlearn_history.phase == 'retrain', 'loss_scale'] = unlearn_history.loc[unlearn_history.phase == 'retrain', 'loss'] /unlearn_history.loc[unlearn_history.phase == 'retrain', 'loss'].max() \n",
        "\n",
        "sns.lineplot(data = unlearn_history, x = 'epoch', y='loss_scale', hue='phase')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Check model performance\n",
        "We now try check the model performance on the retain and forget set. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "models = {'original':model, 'dumb':unlearner.dumb_model, 'erased':unlearner.erased_model, 'retrained':unlearner.retrained_model}\n",
        "dataloaders = {'retain':retain_dataloader, 'forget':forget_dataloader, 'test':testloader}\n",
        "\n",
        "performances = []\n",
        "for model_name, m in models.items():\n",
        "  for dl_name, dl in dataloaders.items():\n",
        "    acc = test(m, dl)\n",
        "    performances.append((model_name, dl_name, acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Strangely the dumb network has 0% performance on the forget set, and this may have a negative impact, note that the performance on the forget set is even too low (we expected 10%, not less).\n",
        "\n",
        "Outside of that we note that this procedure works great for the retain and test which are fitted very nicely, and we can even see that there's a big leap in performance from the erased model to the retrained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "perf_df = pd.DataFrame.from_records(performances, columns=['model', 'data_partition', 'accuracy'])\n",
        "\n",
        "tb = pd.pivot_table(perf_df, index='data_partition', columns='model', values='accuracy')\n",
        "sns.heatmap(tb, annot = True, fmt='.2%')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
