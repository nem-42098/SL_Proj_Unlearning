{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Pre-Trained VGG network\n",
    "> #### https://github.com/chenyaofo\n",
    "> ### Note: There is some issue with using Batch Norm before ReLu as it creates a bias in the network. So people exchange the order between the two for tackling the bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\nmura/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
     ]
    }
   ],
   "source": [
    "### First time when you wan to download the model\n",
    "device=torch.device('cuda')\n",
    "model = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar10_vgg11_bn\", pretrained=True)\n",
    "model=model.to(device)\n",
    "### For future uses:Loading from the local\n",
    "\n",
    "# model_1=torch.hub.load(\"C:/Users/nmura/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\",'hubconf.py',source='local')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check which pre-trained model are available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/chenyaofo/pytorch-cifar-models/zipball/master\" to C:\\Users\\nmura/.cache\\torch\\hub\\master.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cifar100_mobilenetv2_x0_5',\n",
      " 'cifar100_mobilenetv2_x0_75',\n",
      " 'cifar100_mobilenetv2_x1_0',\n",
      " 'cifar100_mobilenetv2_x1_4',\n",
      " 'cifar100_repvgg_a0',\n",
      " 'cifar100_repvgg_a1',\n",
      " 'cifar100_repvgg_a2',\n",
      " 'cifar100_resnet20',\n",
      " 'cifar100_resnet32',\n",
      " 'cifar100_resnet44',\n",
      " 'cifar100_resnet56',\n",
      " 'cifar100_shufflenetv2_x0_5',\n",
      " 'cifar100_shufflenetv2_x1_0',\n",
      " 'cifar100_shufflenetv2_x1_5',\n",
      " 'cifar100_shufflenetv2_x2_0',\n",
      " 'cifar100_vgg11_bn',\n",
      " 'cifar100_vgg13_bn',\n",
      " 'cifar100_vgg16_bn',\n",
      " 'cifar100_vgg19_bn',\n",
      " 'cifar100_vit_b16',\n",
      " 'cifar100_vit_b32',\n",
      " 'cifar100_vit_h14',\n",
      " 'cifar100_vit_l16',\n",
      " 'cifar100_vit_l32',\n",
      " 'cifar10_mobilenetv2_x0_5',\n",
      " 'cifar10_mobilenetv2_x0_75',\n",
      " 'cifar10_mobilenetv2_x1_0',\n",
      " 'cifar10_mobilenetv2_x1_4',\n",
      " 'cifar10_repvgg_a0',\n",
      " 'cifar10_repvgg_a1',\n",
      " 'cifar10_repvgg_a2',\n",
      " 'cifar10_resnet20',\n",
      " 'cifar10_resnet32',\n",
      " 'cifar10_resnet44',\n",
      " 'cifar10_resnet56',\n",
      " 'cifar10_shufflenetv2_x0_5',\n",
      " 'cifar10_shufflenetv2_x1_0',\n",
      " 'cifar10_shufflenetv2_x1_5',\n",
      " 'cifar10_shufflenetv2_x2_0',\n",
      " 'cifar10_vgg11_bn',\n",
      " 'cifar10_vgg13_bn',\n",
      " 'cifar10_vgg16_bn',\n",
      " 'cifar10_vgg19_bn',\n",
      " 'cifar10_vit_b16',\n",
      " 'cifar10_vit_b32',\n",
      " 'cifar10_vit_h14',\n",
      " 'cifar10_vit_l16',\n",
      " 'cifar10_vit_l32']\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(torch.hub.list(\"chenyaofo/pytorch-cifar-models\", force_reload=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downlaoding the Dataset and Creating the Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "### Transformation \n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize( \n",
    "       (0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010) \n",
    "    )\n",
    "])\n",
    "### Pytorch Datasets\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root= './data', train = True,\n",
    "    download =True, transform = transform)\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root= './data', train = False,\n",
    "    download =True, transform = transform)\n",
    "### Dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Forget Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split_dataset,forget_split_dataset=torch.utils.data.random_split(train_dataset,lengths=[45000,5000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forget and Retain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "retain_dataloader = torch.utils.data.DataLoader(train_split_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
    "forget_dataloader=torch.utils.data.DataLoader(forget_split_dataset, batch_size=128, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.normal(m.weight,mean=0,std=20)\n",
    "        m.bias.data.fill_(0.)\n",
    "    elif isinstance(m, nn.Conv2d):\n",
    "        torch.nn.init.normal(m.weight,mean=0,std=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nmura\\AppData\\Local\\Temp\\ipykernel_19560\\250970810.py:6: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "  torch.nn.init.normal(m.weight,mean=0,std=20)\n",
      "C:\\Users\\nmura\\AppData\\Local\\Temp\\ipykernel_19560\\250970810.py:3: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "  torch.nn.init.normal(m.weight,mean=0,std=20)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU(inplace=True)\n",
       "    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (24): ReLU(inplace=True)\n",
       "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "model_random=copy.deepcopy(model)\n",
    "model_random=model_random.apply(init_weights)\n",
    "model_random.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective Function: \n",
    "> ### Criterion: KL divergence Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KL_div(output:np.array,truth:np.array):\n",
    "    \"\"\"\"\"\n",
    "    output: 2D array\n",
    "    truth: 2D array\n",
    "\n",
    "    \"\"\"\"\"\n",
    "    soft=torch.nn.Softmax(dim=1)\n",
    "\n",
    "    ### Applying the siftmax to the outputs of both the networks\n",
    "    output=soft(output)\n",
    "    truth=soft(truth)\n",
    "    \n",
    "    return torch.sum(truth*(torch.log(truth)-torch.log(output))),output.size(0)\n",
    "\n",
    "\n",
    "criterion=nn.KLDivLoss(reduction=\"batchmean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Impair Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 0 tensor(0.9928, device='cuda:0') tensor(4964, device='cuda:0')\n",
      "epochs 1 tensor(0.9924, device='cuda:0') tensor(4962, device='cuda:0')\n",
      "epochs 2 tensor(0.9942, device='cuda:0') tensor(4971, device='cuda:0')\n",
      "epochs 3 tensor(0.9912, device='cuda:0') tensor(4956, device='cuda:0')\n",
      "epochs 4 tensor(0.9928, device='cuda:0') tensor(4964, device='cuda:0')\n",
      "epochs 5 tensor(0.9920, device='cuda:0') tensor(4960, device='cuda:0')\n",
      "epochs 6 tensor(0.9920, device='cuda:0') tensor(4960, device='cuda:0')\n",
      "epochs 7 tensor(0.9940, device='cuda:0') tensor(4970, device='cuda:0')\n",
      "epochs 8 tensor(0.9934, device='cuda:0') tensor(4967, device='cuda:0')\n",
      "epochs 9 tensor(0.9942, device='cuda:0') tensor(4971, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "num_epochs=10\n",
    "\n",
    "for i in range(num_epochs):\n",
    "\n",
    "    num_corr=0\n",
    "    num_items=0\n",
    "    for batch_idx,(inputs,targets) in enumerate(forget_dataloader):\n",
    "\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        #### Original Model\n",
    "        out=model(inputs)\n",
    "\n",
    "        ## random model\n",
    "        with torch.no_grad():\n",
    "            model_random.eval()\n",
    "            out_random=model_random(inputs)\n",
    "            \n",
    "        ###Zero Gradient\n",
    "        optimizer.zero_grad()\n",
    "        ### Loss of the model\n",
    "        soft=torch.nn.Softmax(dim=1)\n",
    "\n",
    "         ### Applying the siftmax to the outputs of both the networks\n",
    "        output=soft(out)\n",
    "        truth=soft(out_random)\n",
    "\n",
    "        loss=criterion(output,truth)\n",
    "        \n",
    "        ### Backward Propogation\n",
    "        loss.backward()\n",
    "\n",
    "        ### Optimization step\n",
    "        optimizer.step()\n",
    "\n",
    "        ###number of correct items\n",
    "        num_corr+=torch.sum(torch.argmax(output,axis=1)==targets)\n",
    "        # print(batch_idx,num_corr)\n",
    "        # print(targets,torch.argmax(output,axis=1))\n",
    "        num_items+=targets.size(0)\n",
    "    \n",
    "        \n",
    "\n",
    "    print('epochs',i,num_corr/num_items,num_corr)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the pre-trained model on CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Push the model to GPU\n",
    "device=torch.device('cuda')\n",
    "model_random=model_random.to(device)\n",
    "# output=model.forward(torch.FloatTensor(test_data[b'data'].numpy()).reshape(-1,3,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2, 0, 2, 4, 2, 4, 4, 0, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 4, 2, 2, 4, 2,\n",
      "        2, 2, 2, 9, 2, 4, 4, 0, 2, 9, 2, 4, 2, 0, 2, 2, 2, 4, 4, 7, 2, 4, 4, 4,\n",
      "        4, 4, 2, 2, 4, 4, 4, 2, 2, 4, 0, 4, 2, 4, 4, 2, 2, 4, 2, 2, 3, 4, 0, 4,\n",
      "        2, 2, 2, 4, 9, 2, 4, 2, 2, 2, 4, 0, 2, 4, 2, 2, 2, 2, 4, 4, 0, 2, 2, 4,\n",
      "        4, 0, 2, 2, 0, 2, 4, 2, 4, 2, 4, 4, 4, 2, 2, 4, 2, 4, 2, 2, 2, 4, 4, 2,\n",
      "        2, 4, 4, 4, 2, 0, 4, 0], device='cuda:0')\n",
      "actual labels tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6, 7, 0, 4, 9,\n",
      "        5, 2, 4, 0, 9, 6, 6, 5, 4, 5, 9, 2, 4, 1, 9, 5, 4, 6, 5, 6, 0, 9, 3, 9,\n",
      "        7, 6, 9, 8, 0, 3, 8, 8, 7, 7, 4, 6, 7, 3, 6, 3, 6, 2, 1, 2, 3, 7, 2, 6,\n",
      "        8, 8, 0, 2, 9, 3, 3, 8, 8, 1, 1, 7, 2, 5, 2, 7, 8, 9, 0, 3, 8, 6, 4, 6,\n",
      "        6, 0, 0, 7, 4, 5, 6, 3, 1, 1, 3, 6, 8, 7, 4, 0, 6, 2, 1, 3, 0, 4, 2, 7,\n",
      "        8, 3, 1, 2, 8, 0, 8, 3], device='cuda:0')\n",
      "tensor([2, 3, 7, 4, 4, 0, 0, 9, 2, 2, 4, 2, 2, 2, 0, 2, 2, 2, 4, 4, 2, 4, 2, 2,\n",
      "        4, 2, 2, 4, 0, 9, 3, 4, 2, 4, 2, 4, 4, 2, 2, 3, 0, 2, 2, 9, 0, 4, 2, 9,\n",
      "        2, 9, 0, 2, 0, 0, 4, 2, 0, 2, 4, 2, 0, 2, 4, 4, 2, 4, 4, 4, 4, 0, 4, 0,\n",
      "        9, 2, 2, 4, 2, 0, 4, 4, 2, 9, 4, 2, 2, 9, 2, 0, 2, 2, 0, 2, 2, 4, 4, 2,\n",
      "        2, 4, 2, 2, 3, 9, 4, 2, 4, 4, 2, 2, 4, 9, 9, 2, 4, 2, 4, 2, 2, 4, 3, 2,\n",
      "        4, 4, 2, 4, 4, 4, 2, 2], device='cuda:0')\n",
      "actual labels tensor([5, 2, 4, 1, 8, 9, 1, 2, 9, 7, 2, 9, 6, 5, 6, 3, 8, 7, 6, 2, 5, 2, 8, 9,\n",
      "        6, 0, 0, 5, 2, 9, 5, 4, 2, 1, 6, 6, 8, 4, 8, 4, 5, 0, 9, 9, 9, 8, 9, 9,\n",
      "        3, 7, 5, 0, 0, 5, 2, 2, 3, 8, 6, 3, 4, 0, 5, 8, 0, 1, 7, 2, 8, 8, 7, 8,\n",
      "        5, 1, 8, 7, 1, 3, 0, 5, 7, 9, 7, 4, 5, 9, 8, 0, 7, 9, 8, 2, 7, 6, 9, 4,\n",
      "        3, 9, 6, 4, 7, 6, 5, 1, 5, 8, 8, 0, 4, 0, 5, 5, 1, 1, 8, 9, 0, 3, 1, 9,\n",
      "        2, 2, 5, 3, 9, 9, 4, 0], device='cuda:0')\n",
      "tensor([4, 0, 2, 2, 4, 4, 4, 4, 2, 2, 4, 4, 9, 0, 0, 0, 4, 4, 2, 0, 2, 4, 2, 4,\n",
      "        4, 3, 0, 2, 2, 2, 2, 9, 2, 4, 4, 4, 2, 2, 4, 2, 4, 2, 2, 4, 4, 2, 4, 4,\n",
      "        4, 2, 2, 2, 4, 4, 2, 4, 2, 0, 2, 9, 2, 4, 4, 2, 0, 2, 4, 4, 2, 2, 3, 2,\n",
      "        2, 3, 3, 0, 2, 4, 4, 2, 3, 2, 0, 4, 0, 4, 2, 2, 2, 4, 9, 7, 0, 2, 4, 3,\n",
      "        9, 2, 0, 2, 0, 9, 2, 4, 4, 2, 2, 2, 2, 9, 4, 2, 4, 2, 2, 2, 4, 2, 4, 2,\n",
      "        0, 4, 4, 4, 4, 2, 0, 2], device='cuda:0')\n",
      "actual labels tensor([3, 0, 0, 9, 8, 1, 5, 7, 0, 8, 2, 4, 7, 0, 2, 3, 6, 3, 8, 5, 0, 3, 4, 3,\n",
      "        9, 0, 6, 1, 0, 9, 1, 0, 7, 9, 1, 2, 6, 9, 3, 4, 6, 0, 0, 6, 6, 6, 3, 2,\n",
      "        6, 1, 8, 2, 1, 6, 8, 6, 8, 0, 4, 0, 7, 7, 5, 5, 3, 5, 2, 3, 4, 1, 7, 5,\n",
      "        4, 6, 1, 9, 3, 6, 6, 9, 3, 8, 0, 7, 2, 6, 2, 5, 8, 5, 4, 6, 8, 9, 9, 1,\n",
      "        0, 2, 2, 7, 3, 2, 8, 0, 9, 5, 8, 1, 9, 4, 1, 3, 8, 1, 4, 7, 9, 4, 2, 7,\n",
      "        0, 7, 0, 6, 6, 9, 0, 9], device='cuda:0')\n",
      "tensor([4, 0, 4, 4, 2, 9, 4, 2, 3, 4, 4, 4, 2, 4, 2, 2, 4, 2, 0, 2, 2, 4, 2, 4,\n",
      "        4, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 4, 4, 4, 2, 2, 0, 2, 2, 2, 4, 0, 4, 2,\n",
      "        2, 4, 2, 4, 2, 4, 4, 4, 2, 2, 2, 2, 2, 4, 2, 2, 0, 2, 2, 2, 4, 2, 2, 2,\n",
      "        4, 2, 4, 2, 4, 4, 2, 2, 2, 0, 2, 2, 3, 4, 4, 0, 2, 2, 4, 2, 2, 9, 4, 9,\n",
      "        0, 4, 9, 4, 4, 9, 2, 4, 2, 4, 4, 2, 2, 2, 2, 2, 2, 4, 4, 2, 4, 2, 4, 4,\n",
      "        9, 2, 2, 2, 0, 4, 4, 4], device='cuda:0')\n",
      "actual labels tensor([2, 8, 7, 2, 2, 5, 1, 2, 6, 2, 9, 6, 2, 3, 0, 3, 9, 8, 7, 8, 8, 4, 0, 1,\n",
      "        8, 2, 7, 9, 3, 6, 1, 9, 0, 7, 3, 7, 4, 5, 0, 0, 2, 9, 3, 4, 0, 6, 2, 5,\n",
      "        3, 7, 3, 7, 2, 5, 3, 1, 1, 4, 9, 9, 5, 7, 5, 0, 2, 2, 2, 9, 7, 3, 9, 4,\n",
      "        3, 5, 4, 6, 5, 6, 1, 4, 3, 4, 4, 3, 7, 8, 3, 7, 8, 0, 5, 7, 6, 0, 5, 4,\n",
      "        8, 6, 8, 5, 5, 9, 9, 9, 5, 0, 1, 0, 8, 1, 1, 8, 0, 2, 2, 0, 4, 6, 5, 4,\n",
      "        9, 4, 7, 9, 9, 4, 5, 6], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model_random.eval()\n",
    "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        out=model_random(inputs)\n",
    "        print(torch.argmax(out,axis=1))\n",
    "        print('actual labels',targets)\n",
    "        \n",
    "        if batch_idx==3:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.8442e+31, -5.0307e+30,  2.1097e+31,  ...,  1.1683e+31,\n",
       "          1.2616e+31,  1.1677e+31],\n",
       "        [ 4.9849e+31, -3.4924e+31,  4.3136e+31,  ...,  1.7350e+31,\n",
       "          8.5682e+30,  4.2503e+31],\n",
       "        [ 1.5537e+31, -1.9391e+31,  2.5463e+31,  ...,  4.4038e+30,\n",
       "          1.0957e+31,  2.6654e+31],\n",
       "        ...,\n",
       "        [ 7.9146e+30, -1.0102e+31,  2.3317e+31,  ...,  2.3273e+31,\n",
       "          1.3055e+31,  1.0298e+31],\n",
       "        [ 2.4701e+31, -2.6977e+31,  1.9855e+31,  ...,  2.3883e+31,\n",
       "          9.3079e+30,  1.8130e+31],\n",
       "        [ 1.3003e+31, -1.2094e+31,  1.7972e+31,  ...,  1.8652e+31,\n",
       "          3.4659e+30,  2.0752e+31]], device='cuda:0')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6, 7, 0, 4, 9,\n",
       "        5, 2, 4, 0, 9, 6, 6, 5, 4, 5, 9, 2, 4, 1, 9, 5, 4, 6, 5, 6, 0, 9, 3, 9,\n",
       "        7, 6, 9, 8, 0, 3, 8, 8, 7, 7, 4, 6, 7, 3, 6, 3, 6, 2, 1, 2, 3, 7, 2, 6,\n",
       "        8, 8, 0, 2, 9, 3, 3, 8, 8, 1, 1, 7, 2, 5, 2, 7, 8, 9, 0, 3, 8, 6, 4, 6,\n",
       "        6, 0, 0, 7, 4, 5, 6, 3, 1, 1, 3, 6, 8, 7, 4, 0, 6, 2, 1, 3, 0, 4, 2, 7,\n",
       "        8, 3, 1, 2, 8, 0, 8, 3], device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.FloatTensor(test_data[b'data'].numpy()).reshape(-1,32,32,3)\n",
    "### normalisation\n",
    "\n",
    "var=x.reshape(10000,-1,3)\n",
    "var_min=var.min(1,keepdim=True)[0]\n",
    "var_min=var_min.unsqueeze(1)\n",
    "\n",
    "var_max=var.max(1,keepdim=True)[0]\n",
    "var_max=var_max.unsqueeze(1)\n",
    "\n",
    "\n",
    "x=(x-var_min)/(x-var_max)\n",
    "### correct input order\n",
    "x=x.permute(0,3,1,2)\n",
    "## standardise\n",
    "x=torchvision.transforms.functional.normalize(x,mean=[0.4914, 0.4822, 0.4465],std=[0.2023, 0.1994, 0.2010])\n",
    "x=x.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 3, 224, 224])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    out=model.forward(x[0:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([300, 10])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(out,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 9,\n",
       " 5,\n",
       " 7,\n",
       " 9,\n",
       " 8,\n",
       " 5,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 0,\n",
       " 4,\n",
       " 9,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 9,\n",
       " 6]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[b'labels'][0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
